{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3ca230-95ff-40f2-abfe-316f50535ad1",
   "metadata": {},
   "source": [
    "Loan Default Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bcac82f-0126-4ea6-b1ce-b8d6aea4a070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fixed script written: train_logreg_full.py\n"
     ]
    }
   ],
   "source": [
    "# Clean rewrite of train_logreg_full.py without escape errors\n",
    "script_fixed = \"\"\"\n",
    "#!/usr/bin/env python3\n",
    "import os, json, zipfile, argparse\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, roc_curve, precision_recall_curve,\n",
    "                             classification_report, confusion_matrix)\n",
    "import joblib\n",
    "\n",
    "def load_csv_from_zip(zip_path, csv_name):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        with z.open(csv_name) as f:\n",
    "            return pd.read_csv(f)\n",
    "\n",
    "def plot_and_save_roc_pr(y_test, y_proba, outdir):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0,1], [0,1], '--', linewidth=0.8)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    roc_path = os.path.join(outdir, 'roc_curve.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(roc_path)\n",
    "    plt.close()\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    ap = average_precision_score(y_test, y_proba)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(recall, precision, label=f'AP = {ap:.4f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    pr_path = os.path.join(outdir, 'pr_curve.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(pr_path)\n",
    "    plt.close()\n",
    "    return roc_path, pr_path\n",
    "\n",
    "def main(args):\n",
    "    zip_path = args.zip\n",
    "    csv_name = args.csvname\n",
    "    outdir = args.outdir\n",
    "    target_col = args.target\n",
    "    top_k = args.top_k\n",
    "    test_size = args.test_size\n",
    "    random_state = args.random_state\n",
    "    max_iter = args.max_iter\n",
    "\n",
    "    Path(outdir).mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Loading data...\", zip_path, csv_name)\n",
    "    df = load_csv_from_zip(zip_path, csv_name)\n",
    "    print(\"Rows, cols:\", df.shape)\n",
    "\n",
    "    if 'ID' in df.columns:\n",
    "        df = df.drop(columns=['ID'])\n",
    "\n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_col}' not found.\")\n",
    "    if df[target_col].dtype == object:\n",
    "        df[target_col] = df[target_col].astype(str).str.strip().str.lower().map(\n",
    "            lambda x: 1 if x in ('1','true','yes','default','charged off','y') else 0)\n",
    "\n",
    "    num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "    if target_col in num_cols:\n",
    "        num_cols.remove(target_col)\n",
    "    cat_cols = df.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
    "\n",
    "    for c in list(cat_cols):\n",
    "        if df[c].nunique(dropna=True) > top_k:\n",
    "            top_vals = df[c].value_counts().nlargest(top_k).index\n",
    "            df[c] = df[c].where(df[c].isin(top_vals), other='__OTHER__')\n",
    "\n",
    "    num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "    if target_col in num_cols:\n",
    "        num_cols.remove(target_col)\n",
    "    cat_cols = df.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
    "\n",
    "    print('Num cols:', len(num_cols), 'Cat cols:', len(cat_cols))\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col].astype(int)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,\n",
    "                                                        stratify=y, random_state=random_state)\n",
    "    print('Train/Test:', X_train.shape, X_test.shape)\n",
    "\n",
    "    num_pipe = Pipeline([('imp', SimpleImputer(strategy='median')), ('sc', StandardScaler())])\n",
    "    cat_pipe = Pipeline([('imp', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                         ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=True))])\n",
    "    preproc = ColumnTransformer([('num', num_pipe, num_cols), ('cat', cat_pipe, cat_cols)], sparse_threshold=0)\n",
    "    clf = Pipeline([('preproc', preproc),\n",
    "                    ('clf', LogisticRegression(solver='saga', max_iter=max_iter, class_weight='balanced'))])\n",
    "\n",
    "    print('Fitting model...')\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('Fitted.')\n",
    "\n",
    "    y_proba = clf.predict_proba(X_test)[:,1]\n",
    "    y_pred = clf.predict(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    ap = average_precision_score(y_test, y_proba)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    clf_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    metrics = {'roc_auc': float(roc_auc),\n",
    "               'average_precision': float(ap),\n",
    "               'confusion_matrix': cm.tolist(),\n",
    "               'classification_report': clf_report}\n",
    "    with open(os.path.join(outdir, 'metrics.json'), 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "\n",
    "    roc_path, pr_path = plot_and_save_roc_pr(y_test, y_proba, outdir)\n",
    "\n",
    "    model_path = os.path.join(outdir, 'logreg_pipeline.joblib')\n",
    "    joblib.dump(clf, model_path, compress=3)\n",
    "\n",
    "    try:\n",
    "        pre = clf.named_steps['preproc']\n",
    "        ohe = None\n",
    "        if len(cat_cols) > 0:\n",
    "            ohe = pre.named_transformers_['cat'].named_steps['ohe']\n",
    "            cat_feature_names = list(ohe.get_feature_names_out(cat_cols))\n",
    "        else:\n",
    "            cat_feature_names = []\n",
    "        feature_names = list(num_cols) + cat_feature_names\n",
    "        coefs = clf.named_steps['clf'].coef_[0]\n",
    "        if len(feature_names) == len(coefs):\n",
    "            coef_df = pd.DataFrame({'feature': feature_names, 'coef': coefs})\n",
    "            coef_df['abs_coef'] = coef_df['coef'].abs()\n",
    "            coef_df = coef_df.sort_values('abs_coef', ascending=False)\n",
    "            coef_df.to_csv(os.path.join(outdir, 'top_coeffs.csv'), index=False)\n",
    "    except Exception as e:\n",
    "        print(\"Could not extract coefficients:\", e)\n",
    "\n",
    "    print('Done. Results in', outdir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--zip', required=True)\n",
    "    parser.add_argument('--csvname', default='Loan_Default.csv')\n",
    "    parser.add_argument('--outdir', default='outputs')\n",
    "    parser.add_argument('--target', default='Status')\n",
    "    parser.add_argument('--top_k', type=int, default=50)\n",
    "    parser.add_argument('--test_size', type=float, default=0.2)\n",
    "    parser.add_argument('--random_state', type=int, default=42)\n",
    "    parser.add_argument('--max_iter', type=int, default=2000)\n",
    "    args = parser.parse_args()\n",
    "    Path(args.outdir).mkdir(parents=True, exist_ok=True)\n",
    "    main(args)\n",
    "\"\"\"\n",
    "with open(\"train_logreg_full.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(script_fixed)\n",
    "print(\"✅ Fixed script written: train_logreg_full.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70fcd5e4-1dfa-4dae-b062-59227cb595ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... D:\\Loan_Default_prediction\\data\\Loan_Default.csv.zip Loan_Default.csv\n",
      "Rows, cols: (148670, 34)\n",
      "Num cols: 11 Cat cols: 21\n",
      "Train/Test: (118936, 32) (29734, 32)\n",
      "Fitting model...\n",
      "Fitted.\n",
      "Done. Results in D:\\Loan_Default_prediction\\outputs\n"
     ]
    }
   ],
   "source": [
    "# In a notebook cell (prefix with ! to run shell command)\n",
    "ZIP_PATH= r\"D:\\Loan_Default_prediction\\data\\Loan_Default.csv.zip\"   # <-- change if your zip is elsewhere\n",
    "CSV_NAME=\"Loan_Default.csv\"\n",
    "OUTDIR= r\"D:\\Loan_Default_prediction\\outputs\"\n",
    "# Increase top_k if you want more categories; reduce if you want fewer features\n",
    "TOP_K=50\n",
    "MAX_ITER=3000\n",
    "\n",
    "# run script (this executes outside the kernel process but prints stdout to the cell)\n",
    "!python train_logreg_full.py --zip \"$ZIP_PATH\" --csvname \"$CSV_NAME\" --outdir \"$OUTDIR\" --target \"Status\" --top_k $TOP_K --max_iter $MAX_ITER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b1de38-eb8c-4a85-ab6d-19ac2d559237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8674082822773999\n",
      "Average Precision: 0.7991069245491025\n",
      "Confusion matrix: [[19740, 2666], [2122, 5206]]\n",
      "Precision/Recall/F1 for class 1: {'precision': 0.6613313008130082, 'recall': 0.7104257641921398, 'f1-score': 0.685}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]], shape=(400, 600, 4), dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]], shape=(400, 600, 4), dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit_type_EQUI</td>\n",
       "      <td>6.446334</td>\n",
       "      <td>6.446334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>credit_type_EXP</td>\n",
       "      <td>-1.966045</td>\n",
       "      <td>1.966045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>credit_type_CIB</td>\n",
       "      <td>-1.934619</td>\n",
       "      <td>1.934619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credit_type_CRIF</td>\n",
       "      <td>-1.898902</td>\n",
       "      <td>1.898902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lump_sum_payment_lpsm</td>\n",
       "      <td>1.604373</td>\n",
       "      <td>1.604373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lump_sum_payment_not_lpsm</td>\n",
       "      <td>-0.957605</td>\n",
       "      <td>0.957605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>submission_of_application_to_inst</td>\n",
       "      <td>0.913650</td>\n",
       "      <td>0.913650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loan_purpose_p2</td>\n",
       "      <td>0.874049</td>\n",
       "      <td>0.874049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LTV</td>\n",
       "      <td>0.869105</td>\n",
       "      <td>0.869105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>occupancy_type_ir</td>\n",
       "      <td>0.847457</td>\n",
       "      <td>0.847457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Neg_ammortization_neg_amm</td>\n",
       "      <td>0.794239</td>\n",
       "      <td>0.794239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Secured_by_land</td>\n",
       "      <td>0.754542</td>\n",
       "      <td>0.754542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>construction_type_mh</td>\n",
       "      <td>0.754542</td>\n",
       "      <td>0.754542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Security_Type_Indriect</td>\n",
       "      <td>0.754542</td>\n",
       "      <td>0.754542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>loan_limit_ncf</td>\n",
       "      <td>0.692879</td>\n",
       "      <td>0.692879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_units_3U</td>\n",
       "      <td>0.582606</td>\n",
       "      <td>0.582606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Upfront_charges</td>\n",
       "      <td>-0.548780</td>\n",
       "      <td>0.548780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>loan_type_type2</td>\n",
       "      <td>0.537172</td>\n",
       "      <td>0.537172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>business_or_commercial_b/c</td>\n",
       "      <td>0.537172</td>\n",
       "      <td>0.537172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>loan_type_type1</td>\n",
       "      <td>0.532561</td>\n",
       "      <td>0.532561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature      coef  abs_coef\n",
       "0                    credit_type_EQUI  6.446334  6.446334\n",
       "1                     credit_type_EXP -1.966045  1.966045\n",
       "2                     credit_type_CIB -1.934619  1.934619\n",
       "3                    credit_type_CRIF -1.898902  1.898902\n",
       "4               lump_sum_payment_lpsm  1.604373  1.604373\n",
       "5           lump_sum_payment_not_lpsm -0.957605  0.957605\n",
       "6   submission_of_application_to_inst  0.913650  0.913650\n",
       "7                     loan_purpose_p2  0.874049  0.874049\n",
       "8                                 LTV  0.869105  0.869105\n",
       "9                   occupancy_type_ir  0.847457  0.847457\n",
       "10          Neg_ammortization_neg_amm  0.794239  0.794239\n",
       "11                    Secured_by_land  0.754542  0.754542\n",
       "12               construction_type_mh  0.754542  0.754542\n",
       "13             Security_Type_Indriect  0.754542  0.754542\n",
       "14                     loan_limit_ncf  0.692879  0.692879\n",
       "15                     total_units_3U  0.582606  0.582606\n",
       "16                    Upfront_charges -0.548780  0.548780\n",
       "17                    loan_type_type2  0.537172  0.537172\n",
       "18         business_or_commercial_b/c  0.537172  0.537172\n",
       "19                    loan_type_type1  0.532561  0.532561"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json, pandas as pd, os, matplotlib.pyplot as plt, IPython.display as disp\n",
    "\n",
    "OUTDIR = \"outputs\"\n",
    "metrics_path = os.path.join(OUTDIR, \"metrics.json\")\n",
    "if os.path.exists(metrics_path):\n",
    "    with open(metrics_path) as f:\n",
    "        metrics = json.load(f)\n",
    "    print(\"ROC AUC:\", metrics.get('roc_auc'))\n",
    "    print(\"Average Precision:\", metrics.get('average_precision'))\n",
    "    print(\"Confusion matrix:\", metrics.get('confusion_matrix'))\n",
    "    # pretty print classification report keys for class '1'\n",
    "    cr = metrics.get('classification_report', {})\n",
    "    if '1' in cr:\n",
    "        print(\"Precision/Recall/F1 for class 1:\", {k: cr['1'].get(k) for k in ('precision','recall','f1-score')})\n",
    "else:\n",
    "    print(\"metrics.json not found in\", OUTDIR)\n",
    "\n",
    "# show plots if created\n",
    "for fn in ['roc_curve.png','pr_curve.png']:\n",
    "    p = os.path.join(OUTDIR, fn)\n",
    "    if os.path.exists(p):\n",
    "        display(plt.imread(p))\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        print(fn, \"not found\")\n",
    "\n",
    "# show top coefficients if available\n",
    "coef_csv = os.path.join(OUTDIR, 'top_coeffs.csv')\n",
    "if os.path.exists(coef_csv):\n",
    "    df_coefs = pd.read_csv(coef_csv)\n",
    "    display(df_coefs.head(20))\n",
    "else:\n",
    "    print(\"No top_coeffs.csv (feature names might not have been extractable).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
